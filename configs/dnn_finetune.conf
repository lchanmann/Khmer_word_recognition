# DNN fine-tunning configuration
HANNET: TRACE = 1
HANNET: MINIBATCHSIZE = 200

HNCACHE: TRACE = 1
HNCACHE: DATAACCESSKIND = FRAMERAND
HNCACHE: SHUFFLEKIND = QUICKNET
HNCACHE: DATACACHESIZE = 200000000

HNTRAINSGD: TRACE = 1
HNTRAINSGD: UPDATEMODE = BATCHLEVEL
HNTRAINSGD: CRITERION = XENT
HNTRAINSGD: EVALCRITERION = XENT|ML
HNTRAINSGD: UPDATETARGETPEN = TRUE
HNTRAINSGD: LOGSTATEOCCWEIGHT = 0.9

HNTRAINSGD: LEARNRATE = 0.0001
HNTRAINSGD: LRSCHEDULER = NEWBOB
HNTRAINSGD: NEWBOBCRT = ACC
HNTRAINSGD: RAMPSTART = 0.001
HNTRAINSGD: STOPDIFF = 0.0001
HNTRAINSGD: DECAYFACTOR = 0.5
HNTRAINSGD: MINEPOCHNUM = 16
HNTRAINSGD: MAXEPOCHNUM = 40
HNTRAINSGD: MOMENTUM = 0.99
HNTRAINSGD: WEIGHTDECAY = 0.001
# HNTRAINSGD: GRADIENTCLIP = 10
HNTRAINSGD: UPDATECLIP = 0.32             # < 0.002
HNTRAINSGD: WEIGHTL2MAXNORMBOUND = 1      # RELU only
# HNTRAINSGD: DROPOUTPROB = 0.5

# DNN train using GPU 0
HCUDA: GPUID = 0

# DNN train using 2 threads mkl
HMATH: NMKLTHREADS = 2
